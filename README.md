# ğŸ¤– ASHIK: GPT

**End-to-End â€¢ Deployment-Ready â€¢ Fully Customizable Agentic AI Chat Platform**

ASHIK: GPT is a **hands-on, end-to-end AI chat application** built to help developers, AI engineers, and founders **learn, customize, and deploy real LLM-powered products** â€” not just demos.

This project provides a **clean UI, modular architecture, and configurable LLM setup**, making it ideal for experimentation as well as real-world AI product development.

---

## âœ¨ Key Features

* ğŸ” **Multi-LLM support** (Groq integrated)
* ğŸ§  **Dynamic model selection** (e.g. LLaMA-3)
* ğŸ” **Secure API key handling**
* ğŸ§© **Modular use-case / workstream architecture**
* ğŸ¨ **Premium, product-grade UI**
* ğŸ•¸ï¸ **Agentic AIâ€“ready (LangGraph compatible)**
* ğŸš€ **End-to-end & deployment-ready**
* âš™ï¸ **Fully customizable**

---

## ğŸ—ï¸ Architecture Overview

```
UI (Streamlit)
   â†“
User Controls & Config
   â†“
LLM Provider (Groq)
   â†“
Agent / Workflow Layer (LangGraph-ready)
   â†“
Response Rendering
```

This structure allows you to:

* Swap LLM providers
* Add new agent workflows
* Extend use cases without touching core UI logic

---

## ğŸ› ï¸ Tech Stack

* **Frontend**: Streamlit (custom styled UI)
* **Backend**: Python
* **LLMs**: Groq (LLaMA-3 models)
* **Agent Framework**: LangGraph (agentic AI)
* **Environment**: Virtualenv / Conda supported

---

## ğŸš€ Getting Started (Run Locally)

Follow these steps to run the project on your system.

---

### 1ï¸âƒ£ Clone the Repository

```bash
git clone <YOUR_GITHUB_REPO_URL>
cd <project-folder>
```

---

### 2ï¸âƒ£ Create & Activate Virtual Environment

#### ğŸ”¹ Using `venv` (recommended)

```bash
python -m venv venv
```

**Activate it:**

* **Windows**

```bash
venv\Scripts\activate
```

* **Mac / Linux**

```bash
source venv/bin/activate
```

---

### 3ï¸âƒ£ Install Requirements

```bash
pip install -r requirements.txt
```

Make sure all dependencies install successfully.

---

### 4ï¸âƒ£ Set Environment Variables (Optional)

You can either:

* Enter your API key directly in the UI
  **OR**
* Set it as an environment variable

```bash
export GROQ_API_KEY=your_api_key_here   # Mac/Linux
set GROQ_API_KEY=your_api_key_here      # Windows
```

---

### 5ï¸âƒ£ Run the Application

```bash
streamlit run app.py
```

Once started, open your browser and go to:

```
http://localhost:8501
```

---

## ğŸ¯ How to Use

1. Select **LLM Provider**
2. Choose the **Model**
3. Enter your **API Key**
4. Select a **Use Case / Workstream**
5. Start chatting ğŸš€

Everything is configurable from the UI â€” no code changes required for basic usage.

---

## ğŸ§© Customization Guide

You can easily:

* â• Add new LLM providers
* â• Add new models
* â• Create new use cases
* â• Plug in agent workflows (LangGraph)

Key configuration files:

```
src/
 â””â”€â”€ langgraphagenticai/
     â””â”€â”€ ui/
         â””â”€â”€ uiconfigfile.py
```

---

## ğŸŒ Deployment

This project is **deployment-ready** and can be hosted on:

* Streamlit Cloud
* AWS / GCP / Azure
* Docker (recommended for production)

---

## ğŸ¤ Contributing

Contributions, suggestions, and improvements are welcome!

1. Fork the repo
2. Create a new branch
3. Make changes
4. Submit a pull request

---

## â­ Support the Project

If this helped you:

* â­ Star the repository
* ğŸ§  Build something on top of it
* ğŸ“£ Share it with others and tag me

Letâ€™s move from **AI demos â†’ AI products**.

---

## ğŸ“¬ Contact

Built by **Ashik Kumar**
If you build something interesting using this, Iâ€™d love to see it ğŸš€

